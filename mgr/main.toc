\babel@toc {polish}{}
\babel@toc {english}{}
\babel@toc {polish}{}
\babel@toc {english}{}
\babel@toc {polish}{}
\babel@toc {english}{}
\babel@toc {english}{}
\babel@toc {polish}{}
\babel@toc {english}{}
\babel@toc {polish}{}
\babel@toc {english}{}
\contentsline {chapter}{\numberline {1}Introduction}{11}{chapter.1}%
\contentsline {section}{\numberline {1.1}Introduction}{11}{section.1.1}%
\contentsline {section}{\numberline {1.2}Use cases}{12}{section.1.2}%
\contentsline {section}{\numberline {1.3}Searching on github}{12}{section.1.3}%
\contentsline {section}{\numberline {1.4}Papers with Code}{13}{section.1.4}%
\contentsline {section}{\numberline {1.5}Code Search}{13}{section.1.5}%
\contentsline {section}{\numberline {1.6}Peculiarities of our problem}{14}{section.1.6}%
\contentsline {section}{\numberline {1.7}Contributions}{16}{section.1.7}%
\contentsline {chapter}{\numberline {2}Theoretical background}{17}{chapter.2}%
\contentsline {section}{\numberline {2.1}Information Retrieval}{17}{section.2.1}%
\contentsline {subsubsection}{\numberline {2.1.0.1}Evaluating Information Retrieval}{18}{subsubsection.2.1.0.1}%
\contentsline {section}{\numberline {2.2}\leavevmode {\color {red}\huge {TODO}}Neural Networks}{18}{section.2.2}%
\contentsline {section}{\numberline {2.3}Neural Networks for unsupervised text feature extraction}{18}{section.2.3}%
\contentsline {subsubsection}{\numberline {2.3.0.1}Classical approaches for text data}{18}{subsubsection.2.3.0.1}%
\contentsline {subsubsection}{\numberline {2.3.0.2}Language modeling}{18}{subsubsection.2.3.0.2}%
\contentsline {subsubsection}{\numberline {2.3.0.3}Why are neural networks useful for NLP?}{19}{subsubsection.2.3.0.3}%
\contentsline {subsubsection}{\numberline {2.3.0.4}Recurrent Neural Networks}{19}{subsubsection.2.3.0.4}%
\contentsline {section}{\numberline {2.4}Neural Language Models}{20}{section.2.4}%
\contentsline {subsection}{\numberline {2.4.1}Word embeddings}{20}{subsection.2.4.1}%
\contentsline {subsection}{\numberline {2.4.2}[\leavevmode {\color {red}\huge {TODO}}???] Attention and Transformer-based models}{22}{subsection.2.4.2}%
\contentsline {section}{\numberline {2.5}Sentence embedding models}{22}{section.2.5}%
\contentsline {subsection}{\numberline {2.5.1}Bi-encoders}{23}{subsection.2.5.1}%
\contentsline {subsubsection}{\numberline {2.5.1.1}Metric learning}{23}{subsubsection.2.5.1.1}%
\contentsline {subsubsection}{\numberline {2.5.1.2}Preparing data for metric learning}{24}{subsubsection.2.5.1.2}%
\contentsline {section}{\numberline {2.6}Zero-shot Learning}{24}{section.2.6}%
\contentsline {section}{\numberline {2.7}Graphs in Machine Learning}{24}{section.2.7}%
\contentsline {subsubsection}{\numberline {2.7.0.1}Graph Neural Networks}{25}{subsubsection.2.7.0.1}%
\contentsline {subsubsection}{\numberline {2.7.0.2}General framework, message passing}{25}{subsubsection.2.7.0.2}%
\contentsline {subsubsection}{\numberline {2.7.0.3}GNN}{26}{subsubsection.2.7.0.3}%
\contentsline {subsubsection}{\numberline {2.7.0.4}Scalability, GraphSAGE}{26}{subsubsection.2.7.0.4}%
\contentsline {subsubsection}{\numberline {2.7.0.5}[\leavevmode {\color {red}\huge {TODO}}???] Deep Graph Infomax}{27}{subsubsection.2.7.0.5}%
\contentsline {chapter}{\numberline {3}Related work}{29}{chapter.3}%
\contentsline {section}{\numberline {3.1}Mining Software Repositories conference}{29}{section.3.1}%
\contentsline {section}{\numberline {3.2}Machine learning and computer code}{29}{section.3.2}%
\contentsline {subsubsection}{\numberline {3.2.0.1}Code Search}{29}{subsubsection.3.2.0.1}%
\contentsline {subsection}{\numberline {3.2.1}Tasks}{30}{subsection.3.2.1}%
\contentsline {subsection}{\numberline {3.2.2}Performance metrics}{30}{subsection.3.2.2}%
\contentsline {subsection}{\numberline {3.2.3}Models}{30}{subsection.3.2.3}%
\contentsline {subsubsection}{\numberline {3.2.3.1}Code2Vec}{30}{subsubsection.3.2.3.1}%
\contentsline {subsubsection}{\numberline {3.2.3.2}CodeSearchNet}{30}{subsubsection.3.2.3.2}%
\contentsline {subsubsection}{\numberline {3.2.3.3}Import2Vec}{30}{subsubsection.3.2.3.3}%
\contentsline {subsection}{\numberline {3.2.4}Attention models}{31}{subsection.3.2.4}%
\contentsline {subsection}{\numberline {3.2.5}Auxillary techniques}{31}{subsection.3.2.5}%
\contentsline {subsection}{\numberline {3.2.6}Challenges}{31}{subsection.3.2.6}%
\contentsline {section}{\numberline {3.3}Programming language-specific feature extraction}{31}{section.3.3}%
\contentsline {section}{\numberline {3.4}Hierarchical structure}{31}{section.3.4}%
\contentsline {chapter}{\numberline {4}Problem statement}{33}{chapter.4}%
\contentsline {section}{\numberline {4.1}Metrics}{33}{section.4.1}%
\contentsline {section}{\numberline {4.2}Repository task retrieval}{34}{section.4.2}%
\contentsline {chapter}{\numberline {5}Data}{35}{chapter.5}%
\contentsline {section}{\numberline {5.1}Raw Data}{35}{section.5.1}%
\contentsline {subsection}{\numberline {5.1.1}Papers}{35}{subsection.5.1.1}%
\contentsline {section}{\numberline {5.2}Train-test split}{36}{section.5.2}%
\contentsline {section}{\numberline {5.3}Extracted datasets}{36}{section.5.3}%
\contentsline {subsection}{\numberline {5.3.1}Python signatures}{37}{subsection.5.3.1}%
\contentsline {section}{\numberline {5.4}Python Dependency graph}{37}{section.5.4}%
\contentsline {subsection}{\numberline {5.4.1}Vertices}{37}{subsection.5.4.1}%
\contentsline {subsection}{\numberline {5.4.2}Edges}{38}{subsection.5.4.2}%
\contentsline {chapter}{\numberline {6}Proposed approach}{39}{chapter.6}%
\contentsline {section}{\numberline {6.1}Introduction}{39}{section.6.1}%
\contentsline {section}{\numberline {6.2}Classical information retrieval}{40}{section.6.2}%
\contentsline {section}{\numberline {6.3}Feature extraction}{40}{section.6.3}%
\contentsline {subsection}{\numberline {6.3.1}Different query and repository features}{40}{subsection.6.3.1}%
\contentsline {section}{\numberline {6.4}Matching queries with repositories}{41}{section.6.4}%
\contentsline {section}{\numberline {6.5}Supervised learning}{41}{section.6.5}%
\contentsline {section}{\numberline {6.6}General ideas}{42}{section.6.6}%
\contentsline {subsection}{\numberline {6.6.1}Shared query and code encoder}{42}{subsection.6.6.1}%
\contentsline {subsection}{\numberline {6.6.2}Using different features for tasks and repositories}{43}{subsection.6.6.2}%
\contentsline {subsection}{\numberline {6.6.3}Combining approaches}{43}{subsection.6.6.3}%
\contentsline {chapter}{\numberline {7}Results}{45}{chapter.7}%
\contentsline {section}{\numberline {7.1}Topline}{45}{section.7.1}%
\contentsline {section}{\numberline {7.2}Results}{45}{section.7.2}%
\contentsline {section}{\numberline {7.3}Detailed results}{46}{section.7.3}%
\contentsline {chapter}{\numberline {8}Future directions}{47}{chapter.8}%
\contentsline {section}{\numberline {8.1}Data sources}{47}{section.8.1}%
\contentsline {subsection}{\numberline {8.1.1}Social media features}{47}{subsection.8.1.1}%
\contentsline {subsection}{\numberline {8.1.2}Heterogenous graph}{47}{subsection.8.1.2}%
\contentsline {subsection}{\numberline {8.1.3}Relations between repositories}{47}{subsection.8.1.3}%
\contentsline {chapter}{Bibliography}{49}{chapter*.14}%
\contentsline {chapter}{\numberline {A}Details}{53}{appendix.A}%
\contentsline {section}{\numberline {A.1}Full list of models}{53}{section.A.1}%
\contentsline {chapter}{\numberline {B}Other experiments}{55}{appendix.B}%
\contentsline {section}{\numberline {B.1}failed_experiments}{55}{section.B.1}%
\contentsline {section}{\numberline {B.2}Zero-shot learning}{55}{section.B.2}%
\contentsline {subsection}{\numberline {B.2.1}Proxy ZSL problem}{55}{subsection.B.2.1}%
\contentsline {section}{\numberline {B.3}GNNs for Supervised learning}{56}{section.B.3}%
\contentsline {subsection}{\numberline {B.3.1}Shared query and code encoder}{56}{subsection.B.3.1}%
\contentsline {chapter}{\numberline {C}Misc}{59}{appendix.C}%
\contentsline {section}{\numberline {C.1}OpenAI API}{59}{section.C.1}%
\contentsline {section}{\numberline {C.2}ChatGPT}{59}{section.C.2}%
\contentsline {paragraph}{\numberline {C.2.0.0.1}\textit {eleuther/gpt-j6B} }{60}{paragraph.C.2.0.0.1}%
\contentsline {paragraph}{\numberline {C.2.0.0.2}\textit {bigscience/bloom}}{60}{paragraph.C.2.0.0.2}%
